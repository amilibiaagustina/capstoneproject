\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts

\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{booktabs}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\begin{document}

\title{Multimodal Data Synchronization and Analysis Pipeline for Closed-Loop Deep Brain Stimulation in Obsessive-Compulsive Disorder}

\author{\IEEEauthorblockN{Maria Agustina Amilibia}
\IEEEauthorblockA{\textit{Department of Electrical and Computer Engineering}\\
\textit{Rice University}\\
Houston, TX, USA\\
In collaboration with Provenza Lab, Baylor College of Medicine\\
ELEC 594 -- Capstone Project Final Report}
}

\maketitle

\begin{abstract}
Closed-loop deep brain stimulation for treatment-resistant obsessive-compulsive disorder requires identifying neural biomarkers that correlate with symptom states. This project develops an end-to-end multimodal data synchronization and analysis pipeline integrating audio-video recordings with intracranial electrophysiology from patients with ventral capsule/ventral striatum electrodes. The system employs Arduino-based hardware synchronization achieving sub-frame accuracy (\textless 33ms), followed by software alignment with local field potential recordings. Analysis of theta-band oscillations (4-8 Hz) revealed a significant negative correlation between left-hemisphere theta power and subjective anxiety ratings (Spearman $\rho$ = -0.126, p = 0.0024). Machine learning classification of stress states achieved 61.5\% accuracy, with left theta emerging as the most predictive feature. These findings suggest left-lateralized theta activity as a potential biomarker for adaptive neuromodulation.
\end{abstract}

\begin{IEEEkeywords}
multimodal synchronization, deep brain stimulation, OCD, local field potentials, theta oscillations, machine learning, biomarker discovery
\end{IEEEkeywords}

\section{Introduction}

Obsessive-compulsive disorder (OCD) and treatment-resistant bipolar depression (TRBD) constitute some of the most challenging psychiatric disorders to treat, as a significant proportion of patients demonstrate poor response to pharmacological strategies alone or in combination with psychotherapeutic approaches \cite{howes2022treatment}. Deep brain stimulation (DBS) targeting the ventral capsule/ventral striatum (VC/VS) has emerged as a potential therapeutic approach for select patients, although clinical outcomes remain inconsistent \cite{gadot2022efficacy}. To improve treatment efficacy, clinicians need to gain a deeper understanding of the neural activity and associated behavioral outcomes that correspond to distinct symptom profiles.

One of the major hurdles in any effort to explore psychiatric neuromodulation is linking neural activity with behavior that we can observe. Examining correlated neural features with behavioral information may provide biomarkers to inform DBS interventions \cite{provenza2024disruption, klumpp2025syntalos, provenza2021longterm}. However, investigating these neural-behavioral relationships requires precise temporal alignment of video recordings with intracranial electrophysiology, as even small timing errors can obscure genuine correlations between behavioral events and neural dynamics.

This project introduces a platform that integrates video, audio, and neural data---including theta-band activity and spectrograms---all collected during real-world clinical observations. The work focuses on: (1) developing infrastructure to precisely align audio-video recordings with local field potential (LFP) data from chronically implanted VC/VS electrodes in OCD patients; (2) implementing signal processing pipelines for neural feature extraction; (3) analyzing relationships between neural oscillations and subjective anxiety ratings; and (4) creating a scalable object-oriented codebase for multi-patient analysis. This multimodal data approach enables clinicians to examine brain-behavior interactions with greater precision, facilitating the development of more individualized and effective treatment strategies.


\section{Methods}

\subsection{Patient Population and Data Collection}

Data were collected from four patients with treatment-resistant OCD who had undergone chronic implantation of bilateral VC/VS DBS electrodes. Each patient participated in four naturalistic recording sessions conducted in clinical settings, yielding sixteen total sessions. Each session lasted approximately 20 minutes and followed an Exposure and Response Prevention (ERP) paradigm. During ERP, patients were first exposed to anxiety-provoking stimuli while instructed to refrain from performing their compulsions (Exposure phase, 6 min), followed by a period where they could engage in compulsions (Compulsions phase, 4 min), and finally a period of relief (Relief phase, 4 min). A Baseline period (2 min) preceded the task.

As shown in Figure~\ref{fig:system_setup}, multimodal data were collected simultaneously to capture both behavioral and neural dynamics throughout the ERP session. Two cameras recorded synchronized behavioral footage from different angles, while an audio channel captured task-related cues. Neural activity from bilateral VC/VS electrodes was recorded via the BrainAmp EXG amplifier system connected to the BrainVision BUA and TriggerBox, which provided hardware timing markers for precise synchronization. An auditory beep generated by the task computer allowed subsequent alignment between the video and neural data. The Percept tablet was used to monitor DBS device parameters during recordings.

\begin{figure}[h!]
\centering
\includegraphics[width=\linewidth]{system.jpeg}
\caption{Multimodal data acquisition and synchronization setup. Experimental configuration used for synchronized recording of behavioral and neural data during ERP sessions. Figure adapted from Bechtold et al., \textit{NER}, 2025.}
\label{fig:system_setup}
\end{figure}

\subsection{Hardware Synchronization System}

The synchronization architecture (Figure~\ref{fig:hardware_system}) employed an Arduino MEGA microcontroller as the central controller responsible for coordinating timing across all data streams. The Arduino generated digital trigger signals that initiated camera recordings and simultaneously produced audio synchronization pulses recorded by the microphone setup. These timing pulses served as reference markers to achieve sub-frame alignment between video and audio during post-processing.

The system included a custom-printed circuit board (PCB) acting as an interface between the Arduino and the cameras. The PCB distributed trigger signals to each camera and received exposure feedback signals for verification, ensuring precise synchronization across multiple camera streams. Cameras were connected to a PC via a PoE Ethernet switch that handled both data transfer and power delivery. Audio was captured using a dual-microphone setup connected to an audio interface and recorded in \textit{Audacity}. The complete configuration enabled reliable temporal synchronization between heterogeneous acquisition systems operating at different sampling rates, forming the foundation for multimodal integration with neural data in subsequent processing steps.

\begin{figure}[h!]
\centering
\includegraphics[width=\linewidth]{diagram.png}
\caption{Hardware synchronization architecture. Schematic of the Arduino-based system used to synchronize camera and audio recordings through trigger pulses and feedback signals. The setup includes a custom PCB, PoE Ethernet switch, microphones, and audio interface integrated with a control PC for synchronized multimodal acquisition.}
\label{fig:hardware_system}
\end{figure}

\subsection{Neural Data Acquisition}

Intracranial local field potentials were recorded from bilateral VC/VS electrodes using clinical neural recording systems. Raw signals were sampled at 250 Hz. Neural recordings operated independently of the audio-video system, requiring software-based post-processing to achieve temporal alignment.

\subsection{Software Integration Pipeline}

Following data collection, a MATLAB-based processing pipeline was implemented to temporally align the multimodal data streams, integrating video, audio, and intracranial neural recordings. First, the synchronization was achieved by matching the audible beep present in the video recordings with the Event Flag generated by the task computer in the LFP data. This provided precise temporal alignment between the behavioral recordings and the neural signals with sub-frame accuracy.

The resulting dataset allowed the generation of synchronized multimodal videos displaying patient behavior in real time alongside neural activity. Each frame included the original video footage, the corresponding left and right VC/VS LFP signals, their filtered theta-band components, and their respective time-frequency spectrograms (Figure~\ref{fig:software_pipeline}). This integrated visualization enables direct examination of temporal relationships between observable behavioral states and neural dynamics, supporting the identification of potential biomarkers for adaptive stimulation control.

\begin{figure}[h!]
\centering
\includegraphics[width=\linewidth]{videoimage.jpeg}
\caption{Output of the software synchronization and visualization pipeline. Example of synchronized multimodal data showing patient behavior, corresponding bilateral VC/VS LFP time-series, theta-band filtered signals, and time-frequency spectrograms for both hemispheres.}
\label{fig:software_pipeline}
\end{figure}

\subsection{Neural Signal Processing and Feature Extraction}

LFP signals underwent preprocessing including: (1) NaN interpolation for missing data, (2) demeaning to remove DC offset, and (3) artifact removal excluding the first 10 seconds and last 5 seconds of each recording to eliminate edge artifacts from stimulation transitions. Band power was calculated for theta (4-8 Hz), alpha (8-12 Hz), and beta (12-30 Hz) frequency bands using 2-second non-overlapping windows via Welch's method.

To enable correlation analysis between neural activity and subjective distress, theta power computed in 2-second windows was aligned with SUDS (Subjective Units of Distress Scale) ratings. Each neural window was assigned the SUDS score from the nearest rating in time, creating paired observations for statistical analysis (Figure~\ref{fig:thetasuds}).  Outliers exceeding 3 standard deviations were removed prior to correlation analysis.

\begin{figure}[h!]
\centering
\includegraphics[width=\linewidth]{thetaandsuds.jpeg}
\caption{Theta band activity alligned to Subjective Units of Distress (SUDs) in left and right hemisphere.}
\label{fig:thetasuds}
\end{figure}

\subsection{Machine Learning Classification}

Two classification approaches were implemented to predict anxiety states from neural features:

\textbf{Model 1 (SUDS-based):} Binary classification of High anxiety ($\geq$ median SUDS) versus Low anxiety ($<$ median SUDS) using 6 features per 2-second window: theta, alpha, and beta power from left and right hemispheres.

\textbf{Model 2 (Phase-based):} Binary classification of Stress (Exposure + Compulsions phases) versus No Stress (Baseline + Relief phases) using identical features. Class imbalance was addressed via random downsampling of the majority class.

Both models employed Logistic Regression and Random Forest classifiers with 75/25 train-test split and 5-fold stratified cross-validation. Feature importance was assessed using Random Forest permutation importance.

\subsection{Object-Oriented Architecture}

To enable scalable multi-patient analysis, the codebase was refactored from procedural scripts into an object-oriented Python structure: \texttt{LFPData} class for loading, preprocessing, and managing patient data; \texttt{BandAnalysis} class for band power calculation, SUDS alignment, and phase analysis; and \texttt{plot\_functions} module for reusable visualization utilities. This architecture allows analysis of any patient with minimal code modification.

\section{Results}

\subsection{System Performance and Data Quality}

The multimodal synchronization system was successfully processed. Hardware synchronization achieved frame-level temporal precision (<33ms) for audio-video alignment. The MATLAB integration pipeline generated synchronized multimodal videos for each session, demonstrating consistent performance across different recording conditions and patient behaviors. Video quality remained sufficient for behavioral observation throughout all sessions. Neural recordings maintained signal quality appropriate for spectral analysis in all sessions.

\subsection{Neural Data Characteristics}

Spectral analysis of VC/VS local field potentials revealed clear theta-band oscillations across all patients and sessions. Theta power showed dynamic fluctuations over the course of recording sessions, with variability both within and across patients. Time-frequency spectrograms demonstrated that theta activity occurred in transient bursts rather than sustained oscillations, consistent with prior literature on VC/VS electrophysiology.

\subsection{Theta-SUDS Correlation Analysis}

Statistical analysis of one patient's data revealed a significant negative correlation between left-hemisphere theta power and SUDS ratings (Spearman $\rho$ = -0.126, p = 0.0024, n = 580 windows after outlier removal), indicating that higher anxiety levels were associated with lower theta power. Pearson correlation showed a similar trend (r = -0.080, p = 0.054). No significant correlations were found for right-hemisphere theta (Spearman $\rho$ = -0.050, p = 0.23) or for alpha and beta bands in either hemisphere (Figure~\ref{fig:thetasudscorrelation}).


\begin{figure}[h!]
\centering
\includegraphics[width=\linewidth]{thetasudscorrelation.jpeg}
\caption{Relationship between subjective distress and theta power in VC/VS DBS recordings.}
\label{fig:thetasudscorrelation}
\end{figure}

\subsection{Phase-Based Theta Differences}

Analysis of theta power distributions across experimental phases revealed significant differences in the left hemisphere. Mann-Whitney U tests showed: Baseline vs Relief (p = 0.0006), Exposure vs Compulsions (p = 0.0099), Exposure vs Relief (p $<$0.0001), and Compulsions vs Relief (p = 0.0085). Relief phase showed the highest theta power (M = 6.6 $\mu$V$^2$, IQR = 8.1), while Exposure showed the lowest (M = 3.2 $\mu$V$^2$, IQR = 4.5). Right hemisphere showed no significant phase differences (all p $>$ 0.05), indicating a left-lateralized effect (Figure~\ref{fig:phases}).

\begin{figure}[h!]
\centering
\includegraphics[width=\linewidth]{phases.jpeg}
\caption{Theta activity in left hemisphere across Baseline, Exposure, Compulsions, and Relief.}
\label{fig:phases}
\end{figure}

\subsection{Machine Learning Results}

SUDS-based classification (Model 1) performed poorly: Logistic Regression achieved 48.4\% accuracy (below 50\% chance level), and Random Forest achieved 66.7\% accuracy but with severe class bias, predicting ``High Anxiety'' almost always and learning no useful neural patterns.

Phase-based classification (Model 2) with balanced data achieved 61.5\% accuracy with balanced recall: 62\% for No Stress and 60\% for Stress, demonstrating above-chance discrimination between experimental stress states. Five-fold cross-validation confirmed model stability: Logistic Regression 57.1\% $\pm$ 4.7\%, Random Forest 55.0\% $\pm$ 3.6\%.

Feature importance analysis revealed theta\_left as the most predictive feature (importance = 0.22), followed by theta\_right (0.17), alpha\_left (0.16), beta\_right (0.16), beta\_left (0.15), and alpha\_right (0.14). This validates the exploratory correlation findings through an independent analytical approach.

\subsection{Integrated Multimodal Visualization}

The primary output of this work consists of synchronized multimodal videos displaying patient behavior alongside neural spectrograms and concurrent clinical symptom severity ratings (SUDS scores). These visualizations enable direct observation of temporal relationships between behavioral states and neural dynamics. Figure~\ref{fig:suds_spectrogram} shows representative frames demonstrating the alignment of SUDS ratings with LFP spectrograms over time.

\begin{figure}[h!]
\centering
\includegraphics[width=\linewidth]{newplot.png}
\caption{Integrated visualization of subjective distress and neural dynamics. SUDS ratings over time alongside left and right VC/VS LFP spectrograms. Vertical dashed lines indicate key clinical events (Exposure start, Compulsions, Relief). This synchronized visualization enables direct observation of relationships between behavioral states and neural oscillatory patterns.}
\label{fig:suds_spectrogram}
\end{figure}

\section{Discussion}

This project successfully developed an end-to-end pipeline for multimodal data synchronization and analysis integrating behavioral video recordings with intracranial electrophysiology in OCD patients undergoing DBS treatment. The system addresses a critical technical requirement for investigating behavioral-neural relationships: precise temporal alignment of heterogeneous data streams acquired through independent recording systems.

The key finding---a significant negative correlation between left-hemisphere theta power and subjective anxiety---suggests that left-lateralized theta activity may serve as a potential biomarker for anxiety states in this population. The observation that theta power is highest during Relief and lowest during Exposure phases suggests theta may track emotional regulation or recovery processes rather than directly indexing anxious arousal. This interpretation aligns with literature implicating theta oscillations in emotional memory consolidation and affect regulation. The lateralized effect to left VC/VS suggests functional hemispheric specialization that warrants further investigation with larger datasets.

Machine learning results demonstrate that phase-based stress states have clearer neural signatures than moment-to-moment SUDS fluctuations, achieving modest but above-chance classification accuracy (61.5\% vs 50\% baseline). The emergence of theta\_left as the most important feature validates the exploratory correlation findings. However, the modest accuracy suggests that frequency band power alone provides limited predictive power; future work should incorporate additional features including theta bursting dynamics, band ratios, hemispheric asymmetry indices, and temporal dynamics.

Current limitations include the preliminary analysis from a single patient, limiting generalizability. The weak SUDS-theta correlation ($\rho$ = -0.126), while statistically significant, indicates substantial unexplained variance. The object-oriented codebase architecture enables scaling to additional patients and integration of multimodal behavioral features from video (facial affect, motion energy) and audio (voice prosody). This infrastructure establishes the foundation for systematic biomarker discovery and eventual development of closed-loop DBS algorithms.

\section*{Acknowledgments}

I thank Dr. Nicole Provenza for the opportunity to contribute to cutting-edge research at the intersection of neuroscience and clinical psychiatry. I am grateful to Victoria Gobo and Raphael Bechtold for technical mentorship and guidance throughout the project development. I also thank Yewen Zhou for software engineering support. This work was supported by Rice University ECE Department and Baylor College of Medicine. Portions of this work were presented at WSSFN 2025 (Buenos Aires, Argentina).

\section*{CRediT Author Statement}

\textbf{Maria Agustina Amilibia:} Conceptualization, Methodology, Software, Validation, Formal analysis, Investigation, Data curation, Visualization, Writing -- Original Draft, Writing -- Review \& Editing, Project administration.\\
\textbf{Victoria Gobo:} Supervision, Methodology, Validation.\\
\textbf{Raphael Bechtold:} Methodology, Resources.\\
\textbf{Nicole Provenza:} Supervision, Conceptualization, Methodology, Resources, Writing -- Review \& Editing, Funding acquisition.


\begin{thebibliography}{00}
\bibitem{howes2022treatment} O. D. Howes, M. E. Thase, and T. Pillinger, ``Treatment resistance in psychiatry: state of the art and new directions,'' \textit{Molecular Psychiatry}, vol. 27, no. 1, pp. 58--72, 2022.

\bibitem{gadot2022efficacy} R. Gadot, R. Najera, S. Hirani, A. Anand, E. Storch, W. K. Goodman, \textit{et al.}, ``Efficacy of deep brain stimulation for treatment-resistant obsessive-compulsive disorder: systematic review and meta-analysis,'' \textit{J. Neurol. Neurosurg. Psychiatry}, vol. 93, no. 11, pp. 1166--1173, 2022.

\bibitem{provenza2024disruption} N. R. Provenza, S. Reddy, A. K. Allam, S. V. Rajesh, N. Diab, G. Reyes, \textit{et al.}, ``Disruption of neural periodicity predicts clinical response after deep brain stimulation for obsessive-compulsive disorder,'' \textit{Nat. Med.}, vol. 30, no. 7, 2024.

\bibitem{klumpp2025syntalos} M. Klumpp, L. Embray, F. Heimburg, A. L. Alves Dias, J. Simon, A. Groh, \textit{et al.}, ``Syntalos: a software for precise synchronization of simultaneous multi-modal data acquisition and closed-loop interventions,'' \textit{Nat. Commun.}, vol. 16, no. 1, p. 708, 2025.

\bibitem{provenza2021longterm} N. R. Provenza, E. R. Matteson, A. B. Allawala, A. Barrios-Anderson, S. A. Sheth, A. Viswanathan, \textit{et al.}, ``Long-term ecological assessment of intracranial electrophysiology synchronized to behavioral markers in obsessive-compulsive disorder,'' \textit{Biol. Psychiatry}, vol. 90, no. 2, 2021.


\end{thebibliography}

\end{document}